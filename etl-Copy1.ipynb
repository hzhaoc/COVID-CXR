{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "spark = pyspark.sql.SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"COVID-CXR META ETL\") \\\n",
    "    .config(\"spark.some.config.option\", \"xxx\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "try:\n",
    "    # once intialized, it's global in the jupyter notebook kernal; one context per notebook\n",
    "    sc = pyspark.SparkContext.getOrCreate('local[*]')\n",
    "except:\n",
    "    sc = pyspark.SparkContext('local[*]')\n",
    "sqlc = pyspark.SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/source/covid-chestxray-dataset-master/metadata.csv'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_PATH_0_META"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_META_0():\n",
    "    # src 0\n",
    "    META_0 = spark.read.csv(INPUT_PATH_0_META, header=True, sep=\",\").rdd\n",
    "    global _src0_url\n",
    "    _src0_url = META_0.url.to_list()  # for duplicates in src 3\n",
    "    META_0 = META_0[META_0.view.isin([\"PA\", \"AP\", \"AP Supine\", \"AP semi erect\", \"AP erect\"])]  # filter views\n",
    "    META_0 = META_0[['patientid', 'filename', 'finding']]\n",
    "    META_0.dropna(axis=0, how='any', inplace=True)\n",
    "    META_0.rename(columns={'patientid': 'patient', 'filename': 'img', 'finding': 'label'}, inplace=True)\n",
    "    META_0['src'] = 0\n",
    "    META_0['label'] = META_0.label.apply(src0_label)\n",
    "    META_0['img'] = META_0.img.apply(lambda path: os.path.join(INPUT_PATH_0_IMG, path))\n",
    "    META_0 = META_0[META_0.label!='other']\n",
    "    return META_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MapPartitionsRDD[189] at javaToPython at <unknown>:0\n",
      "[Row(patientid='2', offset='0', sex='M', age='65', finding='Pneumonia/Viral/COVID-19', RT_PCR_positive='Y', survival='Y', intubated='N', intubation_present='N', went_icu='N', in_icu='N', needed_supplemental_O2='Y', extubated=None, temperature=None, pO2_saturation=None, leukocyte_count=None, neutrophil_count=None, lymphocyte_count=None, view='PA', modality='X-ray', date='January 22, 2020', location='Cho Ray Hospital, Ho Chi Minh City, Vietnam', folder='images', filename='auntminnie-a-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg', doi='10.1056/nejmc2001272', url='https://www.nejm.org/doi/full/10.1056/NEJMc2001272', license=None, clinical_notes='On January 22, 2020, a 65-year-old man with a history of hypertension, type 2 diabetes, coronary heart disease for which a stent had been implanted, and lung cancer was admitted to the emergency department of Cho Ray Hospital, the referral hospital in Ho Chi Minh City, for low-grade fever and fatigue. He had become ill with fever on January 17, a total of 4 days after he and his wife had flown to Hanoi from the Wuchang district in Wuhan, where outbreaks of 2019-nCoV were occurring. He reported that he had not been exposed to a “wet market” (a market where dead and live animals are sold) in Wuhan. Chest radiographs obtained on admission showed an infiltrate in the upper lobe of the left lung', other_notes=None, _c29=None)]\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(INPUT_PATH_0_META, header=True, sep=\",\").rdd\n",
    "print(df)\n",
    "print(df.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-NTGREJQ9.attlocal.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x25cc3e64e48>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dir(spark.read.format):\n",
    "    if i[0] != '_':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SparkContext' object has no attribute 'sqlContext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-cd3d28729064>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msqlContext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqlContext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'SparkContext' object has no attribute 'sqlContext'"
     ]
    }
   ],
   "source": [
    "sqlContext = sc.sqlContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_list = range(10000)\n",
    "rdd = sc.parallelize(big_list, 2)\n",
    "odds = rdd.filter(lambda x: x % 2 != 0)\n",
    "odds.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rdd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-fee4b19893bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrdd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'rdd' is not defined"
     ]
    }
   ],
   "source": [
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSELECT subject_id, sex, dob, ifnull(dod, \"\")\\nFROM PATIENT\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "SELECT subject_id, sex, dob, ifnull(dod, \"\")\n",
    "FROM PATIENT\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.etl import *\n",
    "from src.utils import *\n",
    "import yaml\n",
    "from collections import Counter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['data']['image_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "META = etl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('label distribution: ', Counter(META.label), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "META = dataset_split(META)\n",
    "META.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('label integer map: ', params['train']['labelmap'], sep='\\n', end='\\n\\n')\n",
    "for ds in (0, 1):\n",
    "    print('{0} data from covid datasets: '.format({0: 'test', 1: 'train'}[ds]), Counter(META[META.train==ds].label), sep='\\n', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache image meta\n",
    "if not os.path.isdir(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)\n",
    "with open(os.path.join(SAVE_PATH, 'meta'), 'wb') as pickle_file:\n",
    "    pickle.dump(META, pickle_file, pickle.HIGHEST_PROTOCOL)\n",
    "    print(f\"META data saved at {os.path.join(SAVE_PATH, 'meta')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if False:\n",
    "    # -------------------------------------------------------------------------------------------------------------------\n",
    "    # imagge file to matrix  \n",
    "    # NOTE: this needs model to load all data at once into cache which take up too much storage, \n",
    "    #       making computing inefficient, NOT GOOD\n",
    "    # -------------------------------------------------------------------------------------------------------------------\n",
    "    # train_data / test_data structure: \n",
    "    #                        {'covid': {'data': list of size*size*3 numpy array, 'label': corresponding list of integer},\n",
    "    #                        '!covid': {'data': list of size*size*3 numpy array, 'label': corresponding list of integer}}\n",
    "    TRAIN_DATA, TEST_DATA = datafromfile(META)\n",
    "    # a sanity check\n",
    "    print(f\"train covid sample #: {len(TRAIN_DATA['covid']['label'])}\")\n",
    "    print(f\"train !covid sample #: {len(TRAIN_DATA['!covid']['label'])}\")\n",
    "    print(f\"test  covid sample #: {len(TEST_DATA['covid']['label'])}\")\n",
    "    print(f\"test  !covid sample #: {len(TEST_DATA['!covid']['label'])}\")\n",
    "    # cache image data\n",
    "    with open(os.path.join(SAVE_PATH, 'train.data'), 'wb') as pickle_file:\n",
    "        pickle.dump(TRAIN_DATA, pickle_file, pickle.HIGHEST_PROTOCOL)\n",
    "        print(f\"Image data saved at {os.path.join(SAVE_PATH, 'train.data')}\")\n",
    "    with open(os.path.join(SAVE_PATH, 'test.data'), 'wb') as pickle_file:\n",
    "        pickle.dump(TEST_DATA, pickle_file, pickle.HIGHEST_PROTOCOL)\n",
    "        print(f\"Image data saved at {os.path.join(SAVE_PATH, 'test.data')}\")\n",
    "else:\n",
    "    # merge imgaes together instead, and transform image to batches of matrix during training\n",
    "    mergesoure(META)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check for image shape, they need to consistent with model input\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "for i in np.random.choice(META.index, 10):\n",
    "    print(i, cv2.imread(META.loc[i, 'imgid']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
